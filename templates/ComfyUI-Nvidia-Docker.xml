<?xml version="1.0"?>
<Container version="2">
    <Name>ComfyUI-Nvidia-Docker</Name>
    <Repository>mmartial/comfyui-nvidia-docker</Repository>
    <Registry>https://hub.docker.com/r/mmartial/comfyui-nvidia-docker</Registry>
    <Support>https://forums.unraid.net/topic/172874-support-comfyui-nvidia-docker/</Support>
    <Project>https://github.com/mmartial/ComfyUI-Nvidia-Docker</Project>
    <TemplateURL>https://raw.githubusercontent.com/mmartial/unraid-templates/main/templates/ComfyUI-Nvidia-Docker.xml</TemplateURL>
    <Icon>https://raw.githubusercontent.com/mmartial/unraid-templates/main/templates/img/ComfyUI-Nvidia-Docker.png</Icon>
    <Category>AI: MediaApp:Photos</Category>
    <ExtraSearchTerms>WebUI images generation Stable Diffusion</ExtraSearchTerms>
    <Network>bridge</Network>
    <Requires>**Nvidia Driver plugin**</Requires>
    <MyIP/>
    <Shell>bash</Shell>
    <Privileged>false</Privileged>
    <Overview>
ComfyUI WebUI Dockerfile with Nvidia support, built from the latest official ComfyUI GitHub release.
Install ComfyUI Manager to simplify integration of additional custom nodes.

The tool will create some folders inside the "run directory", among which: HF, ComfyUI and venv

All those folders will be created with the WANTED_UID and WANTED_GID parameters (by default using Unraid's default of 99:100) allowing the end-user to place directly into the folders their checkpoints, unet, lora and other required models.

The container comes with no weights/models; you need to obtain those and install them in the proper directories under the mount you have selected for the "run directory".

Output files will be placed into the ComfyUI/output folder within that "run directory".

Please see https://github.com/mmartial/ComfyUI-Nvidia-Docker for further details.&#xD;
In particular, details about "First time use" (and the "bottle" workflow), noting that Unraid's default YOUR_RUN_DIRECTORY is /mnt/user/appdata/comfyui-nvidia/mnt

Note:&#xD;
- The container requires the Nvidia Driver plugin to be installed on your Unraid server.&#xD;
- This is a WebUI for the ComfyUI Stable Diffusion tool with a Docker image of over 5GB.&#xD;
- The container will take a while to start up, as it needs to download the ComfyUI Stable Diffusion tool and install its dependencies, usually adding another 5GB of downloaded content in the venv folder&#xD;
- The original Docker image is from Nvidia, as such it is governed by the NVIDIA Deep Learning Container License.
    </Overview>
    <Readme>https://github.com/mmartial/ComfyUI-Nvidia-Docker</Readme>
    <Date>2021-09-15</Date>
    <Changes>
### 20240915
- Added `COMFY_CMDLINE_XTRA` variable to allow for additional command line arguments when starting ComfyUI (ex: --fast --reserve-vram 2.0 --lowvram). 
Check the Docker logs if this prevents your container from starting.
### 20240810
- Initial release
    </Changes>
    <WebUI>http://[IP]:[PORT:8188]</WebUI>
    <ExtraParams>--runtime nvidia --gpus all</ExtraParams>
    <PostArgs/>
    <CPUset/>
    <DateInstalled/>
    <DonateText/>
    <DonateLink/>
    <Config Name="WebUI Port" Target="8188" Default="8188" Mode="tcp" Description="" Type="Port" Display="always" Required="true" Mask="false">8188</Config>
    <Config Name="run directory" Target="/comfy/mnt" Default="/mnt/user/appdata/comfyui-nvidia/mnt" Mode="rw" Description="" Type="Path" Display="always" Required="true" Mask="false">/mnt/user/appdata/comfyui-nvidia/mnt</Config>
    <Config Name="WANTED_UID" Target="WANTED_UID" Default="99" Mode="" Description="UID to use for content in run directory" Type="Variable" Display="always" Required="true" Mask="false">99</Config>
    <Config Name="WANTED_GID" Target="WANTED_GID" Default="100" Mode="" Description="GID to use for content in run directory" Type="Variable" Display="always" Required="true" Mask="false">100</Config>
    <Config Name="COMFY_CMDLINE_XTRA" Target="COMFY_CMDLINE_XTRA" Default="" Mode="" Description="Extra command-line options for ComfyUI" Type="Variable" Display="always" Required="false" Mask="false"></Config>
</Container>
